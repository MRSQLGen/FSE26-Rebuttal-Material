# System Overhead Analysis

We further examine the computational overhead of MRSQLGen compared with SelfCheckGPT and LLM-as-a-judge, using GPT-4o as the underlying model for all methods. 

As shown in Table 4, MR-SQLGen consumes more tokens due to generating metamorphic variants for verification, yet its overall cost remains comparable to LLM-as-a-judge and within a practical range for NL2SQL evaluation. Importantly, the per-task latency of MRSQLGen is moderate, only slightly higher than LLM-as-a-judge on both Spider and BIRD, while still offering substantially better detection accuracy.

![](https://raw.githubusercontent.com/Jasper0209/IMAGES/main/img/Supplementary%20Experiments%20for%20Token%20Usage%20and%20Runtime.png)

For example, on the Spider dataset, MRSQLGen consumes 7.9k tokens and 53.9 seconds of latency per task. While this incurs approximately 13 seconds of additional latency compared to LLM-as-a-judge (40.9s), MRSQLGen significantly improves the F1 score from 0.123 to 0.653, representing an absolute gain of +0.53 (a more than 5× relative improvement). In comparison, SelfCheckGPT, while requiring fewer tokens (2.4k) and a lower latency (29.5s), suffers a significant drop in F1 score to 0.117, demonstrating a trade-off where the reduced computational overhead comes at the expense of accuracy. For the BIRD dataset, MRSQLGen requires 13.5k tokens and 73.4 seconds per task, compared to LLM-as-a-judge’s 26.2k tokens and 62.4 seconds. Despite MRSQLGen’s higher time cost (approximately 11 seconds more), it achieves a notable improvement in F1 score, rising from 0.446 to 0.694—an increase of +0.248. These results demonstrate that MRSQLGen offers a better balance of accuracy and computational efficiency compared to both LLM-as-a-judge and SelfCheckGPT, making it a more effective solution for NL2SQL tasks.